---
title: "Final Project"
author: "Team_4 Enigma"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: true
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r include=FALSE}
# The package "ezids" (EZ Intro to Data Science) includes a lot of the helper functions we developed for the course. 
# Some of the frequently used functions are loadPkg(), xkabledply(), xkablesummary(), uzscale(), etc.
library(ezids)
 
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
```

## Installing Required Packages

```{r Packages}
#install.packages("ggplot2")
#install.packages("dplyr")
#install.packages("corrplot")

library(ggplot2)
library(dplyr)
library(corrplot)

```

## Data Preprocessing

For the data preprocessing part, we will do three things for now:

-   Load the Dataset

-   Check for Missing Values

-   Check Variable Datatypes & Typecast if necessary

```{r load and view data}
setwd <- "C:\\Users\\YASH KATTIMANI\\Downloads\\data.csv"
df <- read.csv("C:\\Users\\YASH KATTIMANI\\Downloads\\data.csv", sep=";")
df
```

```{r DataFrame Information}
# Assuming df is your data frame
str(df)
summary(df)
dim(df)
```

**Observations:** - The dataset contains 4,424 observations and 37 variables, indicating a moderately sized dataset with a diverse range of features. - Variable types include integers (e.g., Marital.status, Application.mode), numerics (e.g., Previous.qualification..grade., Admission.grade), and a character variable (Target). - Summary statistics (like min, max, median) suggest a mix of categorical (e.g., Gender, International) and continuous variables (e.g., Unemployment.rate, GDP). - Several variables, such as Curricular.units.*.sem..*, contain detailed academic information.

```{r Check for Missing Values}
null_values <- sum(is.na(df))
print(null_values)
colSums(is.na(df))
```

```{r Descriptive Statistics Transposed}
df_numeric <- df[sapply(df, is.numeric)]
desc_stats <- sapply(df_numeric, summary)
t(desc_stats)
```

**Observations:**

-   The dataset spans a range of variables, predominantly integers and numerics, with values varying widely, like Course (33 to 9991) and Age.at.enrollment (17 to 70).
-   Several binary or categorical variables, such as Displaced, Gender, and Educational.special.needs, predominantly take values of 0 or 1, indicating binary or dichotomous data.
-   Key continuous variables like Previous.qualification..grade. and Admission.grade show a broad range of values, indicating diverse academic achievements and qualifications among the subjects.

```{r Value Counts of Target Column}
table(df$Target)
```

**Observations:**

-   The 'Target' column predominantly consists of 'Graduate' status with 2,209 occurrences, indicating a majority of the observations in this category.
-   'Dropout' cases are also significant with 1,421 instances, followed by 'Enrolled' status which is the least frequent at 794 cases, reflecting different outcomes in the educational context of the dataset.

```{r Encode Target Column}
df$Target <- as.integer(factor(df$Target))
df$Target
```

**Observations:**

-   The factor() function in converts the 'Target' column into a factor, assigning each unique string an internal integer code, establishing a categorical variable.
-   as.integer() then transforms these factor levels into explicit integer values, starting from 1, providing a numeric representation of each category suitable for analytical models and calculations.
-   This works similar to the "Label Encoder"

```{r Distribution Plot with Density Curve}
library(ggplot2)

# Create the histogram with a density plot overlay
ggplot(df, aes(x = Target)) +
  geom_histogram(aes(y = ..density..), binwidth = 1, fill = "yellow", color = "black") +
  geom_density(alpha = .2, fill = "purple") +
  theme_minimal() +
  labs(title = "Distribution of Target with Density Curve", x = "Target", y = "Density")

```

**Observations:**

-   The above histogram visualizes the frequency distribution of encoded categorical data in the 'Target' column, with the x-axis representing the encoded categories and the y-axis showing the count of observations.
-   The highest bar corresponds to category 3, suggesting it's the mode of the dataset, while category 2 has the lowest frequency, indicating it is the least common outcome in the 'Target' variable.
-   Given the unequal distribution, we can infer a potential imbalance in the dataset's 'Target' classes.
-   The density curve suggests a multimodal distribution of the 'Target' variable, with distinct peaks at each of the integer values that correspond to the categorical classes, reflecting a discrete distribution rather than a continuous one.

```{r Target Variable Pie Chart}
library(ggplot2)

# Create a dataframe from the table to use in ggplot2
pie_data <- as.data.frame(table(df$Target))
names(pie_data) <- c('Category', 'Count')

# We assume that the categories are encoded as follows:
# 1 - Graduate, 2 - Dropout, 3 - Enrolled
# You should adjust the factor levels based on your actual data encoding
pie_data$Category <- factor(pie_data$Category, levels = c(1, 2, 3),
                            labels = c("Graduate", "Dropout", "Enrolled"))

# Create labels with percentages
pie_data$Label <- paste0(pie_data$Category, "\n", round((pie_data$Count / sum(pie_data$Count) * 100), 2), "%")

# Define colors for each category
colors <- c("Graduate" = "skyblue", "Dropout" = "lightcoral", "Enrolled" = "lightgreen")

# Create a pie chart
ggplot(pie_data, aes(x = "", y = Count, fill = Category)) +
  geom_bar(width = 1, stat = "identity") +
  coord_polar(theta = "y", start = 0) +
  theme_void() +
  theme(legend.position = "top") +
  scale_fill_manual(values = colors) +
  geom_text(aes(label = Label), position = position_stack(vjust = 0.5)) +
  labs(title = "Education Status") +
  theme(plot.title = element_text(hjust = 0.5, size = 22, face = "bold"),
        legend.text = element_text(size = 14),
        legend.title = element_blank())

```

**Observations:**

-   Graduate shows us that 32% of individuals in the dataset completed education.
-   Dropout shows us that 17.95% of individuals in the dataset did not complete their education.
-   Enrolled shows us that nearly 50% of individuals in the dataset are currently enrolled in education.

```{r}
# Assuming you have the necessary library installed
library(ggplot2)

# Set the size of the plot
options(repr.plot.width = 8, repr.plot.height = 8)

# Create a pie chart for Gender
gender_data <- table(df$Gender)
gender_labels <- c('Male', 'Female')

# Create a data frame for ggplot
gender_df <- data.frame(labels = gender_labels, values = gender_data)
```

```{r Gender spread}
# Assuming you have the necessary library installed
library(ggplot2)

# Plot the pie chart using ggplot2
ggplot(gender_df, aes(x = "", y = values.Freq, fill = labels)) +
  geom_bar(stat = "identity", width = 1, color = "white", size = 1) +
  coord_polar(theta = "y") +
  theme_void() +
  theme(legend.position = "bottom") +
  ggtitle("Gender") +
  geom_text(aes(label = sprintf("%1.2f%%", values.Freq / sum(gender_data) * 100)),
            position = position_stack(vjust = 0.5), size = 4)

```

```{r Clean Heatmap, fig.width=12, fig.height=10}
library(ggplot2)
library(reshape2)

# Calculate the correlation matrix
corr_matrix <- cor(df, method = "pearson")

# Melt the correlation matrix for ggplot
melted_cormat <- melt(corr_matrix)

# Plot the heatmap
heatmap_plot <- ggplot(melted_cormat, aes(Var2, Var1, fill = value)) +
  geom_tile(color = "black") +
  scale_fill_gradient2(low = "green", high = "orange", mid = "white", midpoint = 0, limit = c(-1, 1), space = "Lab", name="Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, size = 13),
        axis.text.y = element_text(angle = 0, hjust = 1, size = 13),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        legend.position = "right",
        legend.key.size = unit(1.5, 'cm'),
        plot.title = element_text(size = 16)) +
  labs(title = "Variables Pearson Correlation") +
  coord_fixed()

# Print the plot
print(heatmap_plot)
```

**Observation:**

-   There are several variables with high positive correlation, indicated by the light orange squares off the diagonal, which may suggest redundancy between these variables.
-   The majority of variables exhibit low to no correlation with each other, as seen by the prevalence of light squares, indicating independent relationships.
-   The green to white squares suggest negative correlations, though these appear less frequently, indicating fewer inversely related variables in the dataset.

```{r Correlation with Target}
# Assuming 'df' is your dataframe and it's been appropriately pre-processed
# Compute the correlation matrix
corr_matrix <- cor(df)

# Subset the correlation matrix for "Target" and the specified variables
# Use the exact column names as they appear in your dataframe
target_correlations <- corr_matrix["Target", c("Tuition.fees.up.to.date", "Curricular.units.1st.sem..approved.", "Curricular.units.1st.sem..grade.", "Curricular.units.2nd.sem..approved.", "Curricular.units.2nd.sem..grade.")]
target_correlations
```

**Observation**: - The number of "Enrolled" students is meaningless because we are predicting whether or not a student would drop out. All we need to know is if a student completed their education or not. Thus, we will no longer be using the "Enrolled" values and will instead be using the "Graduate" and "Dropout" values.

```{r}
# Remove rows where 'Target' equals 1 which represents enrolled values
df <- df[df$Target != 1, ]
df
```

```{r}
# Create the 'Dropout' column correctly
df$Dropout <- ifelse(df$Target == 3, 1, 0)

# Check the table for 'Dropout' column
table(df$Dropout)


```

```{r Distribution of Dropout}
library(ggplot2)

# Assuming 'df' is your data frame and 'Dropout' is the binary column of interest
ggplot(df, aes(x = Dropout)) +
  geom_histogram(aes(y = ..density..), fill = "red", color = "black", bins = 30) +
  geom_density(color = "black", adjust = 1) +
  theme_classic() +
  labs(title = "Distribution of Dropout", x = "Dropout", y = "Density")+
  scale_x_continuous(limits = c(-0.4, 1.4))
```

**Observations:** - The histogram with overlaid density plot indicates a binary distribution for the 'Dropout' variable, with distinct spikes at 0 and 1, corresponding to the two categories of 'Graduate' and 'Dropout'. - The density peaks suggest that the data is not uniformly distributed; instead, it shows clear categorization, which is consistent with the binary nature of the data. - The x-axis extension beyond the actual data range (0 and 1) to -0.4 and 1.4 allows for a full view of the kernel density estimation, ensuring the tails are visible and not cut off by the plot edges.

```{r Dropout Status Pie Chart}
library(ggplot2)

# Create a dataframe suitable for ggplot2
dropout_counts <- as.data.frame(table(df$Dropout))
names(dropout_counts) <- c("Dropout", "Freq")

# Define labels for the pie chart
dropout_counts$Label <- ifelse(dropout_counts$Dropout == 1, 'Graduate', 'Dropout')

# Plot the pie chart
ggplot(dropout_counts, aes(x = "", y = Freq, fill = Label)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +
  theme_void() +
  theme(legend.position = "top") +
  labs(title = "Dropout Status") +
  geom_text(aes(label = sprintf("%1.2f%%", Freq / sum(dropout_counts$Freq) * 100)),
            position = position_stack(vjust = 0.5)) +
  scale_fill_manual(values = c("Graduate" = "skyblue", "Dropout" = "red"))
```

**Observations:**

-   The pie chart indicates that 73.56% of students are graduates, which is significantly higher than the 26.44% who are dropouts, suggesting a higher tendency towards completion of studies within the observed cohort.
-   The distribution demonstrates a clear majority of successful academic outcomes, with the proportion of graduates more than doubling that of dropouts, which could imply effective retention strategies or a selection of students with a higher likelihood of graduating.

```{r}
# Load necessary libraries
library(dplyr)
library(caret)

# Assuming 'df' is your data frame
# Select the columns for scaling. If you want to select the first 36 columns:
x <- df[, 1:36]

# Print the original values
print(x)

# Apply standard scaling
scaled_x <- scale(x)

# Print the scaled data
print(scaled_x)

```

```{r}
# Assuming 'df' is your data frame and 'Dropout' is the column of interest
y <- df$Dropout

# If you want to explicitly convert it to a vector, you can use the as.vector function
y <- as.vector(df$Dropout)

# Print the 'y' values
print(y)

```

## Exploratory Data Analysis

1Q) How is the distribution of 'Age at Enrollment' in the dataset ?

```{r}
# Assuming you have the necessary library installed
library(ggplot2)

ggplot(df, aes(x = Age.at.enrollment)) +
  geom_histogram(binwidth = 1, fill = "skyblue", color = "white") +
  labs(x = "Age at Enrollment", y = "Number Of Students", title = "Distribution of Age at Enrollment")

```

Q)  What is the count of 'Gender' in the dataset?

```{r}
ggplot(df, aes(x = factor(Gender))) +
  geom_bar(aes(fill = factor(Gender)), color = "white") +
  labs(x = "Gender", y = "Total Number of Students", title = "Count of Gender") +
  scale_x_discrete(labels = c("0" = "Male", "1" = "Female")) +
  scale_fill_manual(name = "Gender", values = c("0" = "lightblue", "1" = "lightpink"),
                    labels = c("0" = "Male", "1" = "Female")) +
  theme_minimal()


```

Q)  How does 'Curricular Units 1st Semester Grade' vary with 'Curricular Units 2nd Semester Grade' for different 'Target' values?

```{r}
ggplot(df, aes(x = Curricular.units.1st.sem..grade., y = Curricular.units.2nd.sem..grade., color = factor(Target))) +
  geom_point() +
  labs(x = "1st Semester Grade", y = "2nd Semester Grade", title = "Grade Comparison by Target")
```

## Smart Questions

Q)  Does a students average grade in their courses have any bearing on their decision to continue or discontinue their studies in the program?

```{r Smart Questions1}
library(ggplot2)

df$Average_Grade <- rowMeans(df[, c("Curricular.units.1st.sem..grade.", "Curricular.units.2nd.sem..grade.")], na.rm = TRUE)

# Now create a boxplot to compare the average grades between the two groups.
ggplot(df, aes(x = as.factor(Target), y = Average_Grade, fill = as.factor(Target))) +
  geom_boxplot() +
  labs(x = "Status", y = "Average Grade", fill = "Student Status") +
  scale_fill_manual(values = c("red", "blue"), labels = c("Discontinued", "Continued")) +
  theme_minimal() +
  theme(legend.title = element_blank()) + 
  ggtitle("Impact of Average Grade on Student Continuation")

# If you want to use a violin plot instead of a boxplot:
ggplot(df, aes(x = as.factor(Target), y = Average_Grade, fill = as.factor(Target))) +
  geom_violin(trim = FALSE) +
  labs(x = "Status", y = "Average Grade", fill = "Student Status") +
  scale_fill_manual(values = c("red", "blue"), labels = c("Discontinued", "Continued")) +
  theme_minimal() +
  theme(legend.title = element_blank()) + 
  ggtitle("Impact of Average Grade on Student Continuation")


```

```{r}
# Assuming 'df' is your data frame
library(ggplot2)

# Scatter plot
ggplot(df, aes(x = Curricular.units.1st.sem..grade., y = Curricular.units.2nd.sem..grade., color = factor(Target_Label))) +
  geom_point() +
  theme_minimal() +
  labs(title = "Curricular Units Grade Variation by Target",
       x = "1st Semester Grade",
       y = "2nd Semester Grade",
       color = "Target") +
  scale_color_brewer(palette = "Set1") +
  guides(color = guide_legend(title = "Target")) +
  theme(legend.position = "top")


```

```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(tidyr)

# Select relevant columns
curricular_cols <- c("Curricular.units.1st.sem..credited.",
                     "Curricular.units.1st.sem..enrolled.",
                     "Curricular.units.1st.sem..evaluations.",
                     "Curricular.units.1st.sem..approved.",
                     "Curricular.units.1st.sem..grade.",
                     "Curricular.units.1st.sem..without.evaluations.",
                     "Curricular.units.2nd.sem..credited.",
                     "Curricular.units.2nd.sem..enrolled.",
                     "Curricular.units.2nd.sem..evaluations.",
                     "Curricular.units.2nd.sem..approved.",
                     "Curricular.units.2nd.sem..grade.",
                     "Curricular.units.2nd.sem..without.evaluations.")

# Subset the dataframe
curricular_df <- df[, c("Dropout", curricular_cols)]

# Pivot the data for easier plotting
curricular_df_long <- curricular_df %>%
  pivot_longer(cols = -Dropout, names_to = "Variable", values_to = "Value")

# Plotting trends in curricular units for dropouts and non-dropouts
ggplot(curricular_df_long, aes(x = Variable, y = Value, fill = factor(Dropout))) +
  geom_boxplot(show.legend = TRUE) +
  facet_wrap(~ Dropout, scales = "free_y", ncol = 2) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  labs(title = "Trends in Curricular Units for Dropouts and Non-Dropouts",
       x = "Curricular Units",
       y = "Value",
       fill = "Dropout Status") +
  scale_fill_manual(values = c("0" = "green", "1" = "red"),
                    labels = c("Continue studying", "Discontinue studying"),
                    name = "Dropout Status") +
  theme(legend.position = "bottom")
```

```{r}
library(ggplot2)
library(dplyr)

# Assuming 'df' is your data frame and 'Target' indicates whether a student dropped out (1) or not (0).
# 'Curricular.units.1st.sem..grade.' and 'Curricular.units.2nd.sem..grade.' indicate the grades.

# First, you might want to create a 'Semester' variable if you don't already have one, 
# or decide how to combine 1st and 2nd semester data.

# For this example, I'll create a simplified analysis for just one semester's grades.
# Adjust this example if you need to include both semesters or if you have a better indicator of semester time.

# Calculate average grade per semester for all students and for dropouts
semester_analysis <- df %>%
  group_by(Target) %>%
  summarise(
    Average_Grade_1st_Sem = mean(Curricular.units.1st.sem..grade., na.rm = TRUE),
    Average_Grade_2nd_Sem = mean(Curricular.units.2nd.sem..grade., na.rm = TRUE)
  )

# Plotting the average grades by dropout status
ggplot(semester_analysis, aes(x = factor(Target), y = Average_Grade_1st_Sem)) +
  geom_bar(stat = "identity", position = position_dodge(), fill = "blue") +
  geom_bar(aes(y = Average_Grade_2nd_Sem), stat = "identity", position = position_dodge(), fill = "red") +
  labs(x = "Status (0 = Continued, 1 = Dropped Out)", y = "Average Grade") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  scale_x_discrete(labels = c("Dropped Out", "Continued")) +
  ggtitle("Average Grades by Dropout Status")

# Note: This is a very simplified example and may need to be adjusted to better fit your analysis needs.
```

\

```{r}
# Assuming 'df' is your data frame and 'Target' indicates whether a student dropped out (1) or not (0).
# 'Curricular.units.1st.sem..grade.' and 'Curricular.units.2nd.sem..grade.' indicate the grades.

# First, you might want to create a 'Semester' variable if you don't already have one, 
# or decide how to combine 1st and 2nd semester data.

# For this example, I'll create a simplified analysis for just one semester's grades.
# Adjust this example if you need to include both semesters or if you have a better indicator of semester time.

# Calculate average grade per semester for all students and for dropouts
semester_analysis <- df %>%
  group_by(Target) %>%
  summarise(
    Average_Grade_1st_Sem = mean(Curricular.units.1st.sem..grade., na.rm = TRUE),
    Average_Grade_2nd_Sem = mean(Curricular.units.2nd.sem..grade., na.rm = TRUE)
  )

# Plotting the average grades by dropout status
ggplot(semester_analysis, aes(x = factor(Target), y = Average_Grade_1st_Sem)) +
  geom_bar(stat = "identity", position = position_dodge(), fill = "blue") +
  geom_bar(aes(y = Average_Grade_2nd_Sem), stat = "identity", position = position_dodge(), fill = "red") +
  labs(x = "Status (0 = Continued, 1 = Dropped Out)", y = "Average Grade") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  scale_x_discrete(labels = c("Continued", "Dropped Out")) +
  ggtitle("Average Grades by Dropout Status")

```

\

```{r}
library(ggplot2)
library(dplyr)

# Assuming `df` is your dataframe and `dropout_indicator` is a binary variable where 1 indicates a dropout
# Replace `Semester_Time_Variable` with your semester time-related variable

# Calculating potential causes averages for each semester
avg_causes_by_semester <- df %>%
  group_by(Daytime.evening.attendance.) %>%
  summarise(
    Avg_Admission_Grade = mean(Admission.grade, na.rm = TRUE),
    Avg_Age_Enrollment = mean(Age.at.enrollment, na.rm = TRUE),
    Percent_Scholarship = mean(Scholarship.holder, na.rm = TRUE) * 100,
    Avg_Parent_Qualification = (mean(Mother.s.qualification, na.rm = TRUE) + mean(Father.s.qualification, na.rm = TRUE)) / 2,
    Avg_Unemployment_Rate = mean(Unemployment.rate, na.rm = TRUE),
    Avg_Inflation_Rate = mean(Inflation.rate, na.rm = TRUE),
    Avg_GDP = mean(GDP, na.rm = TRUE)
  )

# Creating the dropout count by semester
dropout_count_by_semester <- df %>%
  group_by(Daytime.evening.attendance.) %>%
  summarise(Dropouts = sum(Target))

# Creating the plot
ggplot() +
  geom_bar(data = dropout_count_by_semester, aes(x = Daytime.evening.attendance., y = Dropouts), stat = "identity", fill = "steelblue") +
  geom_line(data = avg_causes_by_semester, aes(x = Daytime.evening.attendance., y = Avg_Admission_Grade), group = 1, color = "red") +
  geom_line(data = avg_causes_by_semester, aes(x = Daytime.evening.attendance., y = Avg_Age_Enrollment), group = 1, color = "green") +
  geom_line(data = avg_causes_by_semester, aes(x = Daytime.evening.attendance., y = Percent_Scholarship), group = 1, color = "orange") +
  geom_line(data = avg_causes_by_semester, aes(x = Daytime.evening.attendance., y = Avg_Parent_Qualification), group = 1, color = "purple") +
  geom_line(data = avg_causes_by_semester, aes(x = Daytime.evening.attendance., y = Avg_Unemployment_Rate), group = 1, color = "brown") +
  geom_line(data = avg_causes_by_semester, aes(x = Daytime.evening.attendance., y = Avg_Inflation_Rate), group = 1, color = "pink") +
  geom_line(data = avg_causes_by_semester, aes(x = Daytime.evening.attendance., y = Avg_GDP), group = 1, color = "yellow") +
  labs(title = "Trends in Student Dropouts and Potential Causes by Semester", x = "Semester", y = "Count / Average Value") +
  theme_minimal()
```

## Train & Test Splitting the Data

```{r}
# Load the caret package
library(caret)

# Set seed for reproducibility
set.seed(1)

# Create a partition to split the data
partition <- createDataPartition(y, p = 0.8, list = FALSE)

# Split the data into training and test sets
x_train <- scaled_x[partition, ]
x_test <- scaled_x[-partition, ]
y_train <- y[partition]
y_test <- y[-partition]

# Print out the dimensions to verify the splits
print(dim(x_train))
print(dim(x_test))
print(length(y_train))
print(length(y_test))

```

## Function to Measure Performance

```{r}
# Install necessary packages if they are not already installed
#install.packages("caret")
#install.packages("e1071")

# Load necessary libraries
library(caret)
library(e1071)

perform <- function(y_pred, y_test) {
  # Create a factor version of y_test and y_pred to ensure levels are consistent
  y_test_factor <- factor(y_test, levels = c(0, 1))
  y_pred_factor <- factor(y_pred, levels = c(0, 1))
  
  # Calculate metrics
  precision <- posPredValue(y_pred_factor, y_test_factor, positive = "1")
  recall <- sensitivity(y_pred_factor, y_test_factor, positive = "1")
  accuracy <- sum(y_pred == y_test) / length(y_test)
  f1 <- (2 * precision * recall) / (precision + recall)
  
  # Print metrics
  cat("Precision:", precision, "\n")
  cat("Recall:", recall, "\n")
  cat("Accuracy:", accuracy, "\n")
  cat("F1 Score:", f1, "\n")
  
  # Confusion matrix
  cm <- confusionMatrix(y_pred_factor, y_test_factor)
  print(cm$table)
  cat("\n\n")
  
  # Classification report
  cat(rep("**", 27), "\n", rep(" ", 16), "Classification Report\n", rep("**", 27), "\n")
  print(cm$byClass)
  cat(rep("**", 27), "\n")
  
  # Confusion matrix plot
  plot(cm$table, main="Confusion Matrix")
}

# Example usage (assuming y_pred and y_test are available):
# perform(y_pred, y_test)


```

## Random Forest

```{r}
#install.packages("randomForest")
library(randomForest)

# Convert y_train to a factor to ensure randomForest performs classification
y_train <- factor(y_train)

# Train the Random Forest model
model_rf <- randomForest(x_train, y_train, ntree = 500, mtry = sqrt(ncol(x_train)), importance = TRUE)

```

```{r}
# Make predictions on the test set
y_pred_rf <- predict(model_rf, x_test)
```

```{r}
# Evaluate the model performance using the 'perform' function we defined earlier
perform(y_pred_rf, y_test)
```

```{r Confusion Matrix RF}

library(ggplot2)

# Create the confusion matrix
conf_matrix <- table(Predicted = y_pred_rf, True = y_test)

# Convert the matrix to a data frame for plotting
conf_matrix_df <- as.data.frame(as.table(conf_matrix))

# Create labels for the plot
levels(conf_matrix_df$True) <- c("Dropout", "Non-Dropout")
levels(conf_matrix_df$Predicted) <- c("Dropout", "Non-Dropout")

# Plot the confusion matrix
ggplot(data = conf_matrix_df, aes(x = Predicted, y = True, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = Freq), vjust = 1.5, color = "black") +
  scale_fill_gradient(low = "orange", high = "green") +
  labs(x = "Predicted Label", y = "True Label") +
  theme_minimal() +
  labs(title = "Random Forrest: Confusion Matrix") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

**Observation:**

-   High Specificity: The model has a high specificity (93.8%), which means it's very effective at identifying true negatives, or in this context, the students who are not going to dropout.
-   Good Precision: With a precision of 87.4%, when the model predicts a student will dropout, it's correct most of the time. However, it's somewhat less reliable than specificity, indicating there may be false positives.
-   Moderate Sensitivity: The sensitivity of 59.1% shows that the model is less adept at identifying true positives, meaning there's a higher chance of false negatives, or failing to flag students who may dropout.
-   Overall Accuracy: An overall accuracy of 85.2% suggests that the model is quite accurate in general, but there's room for improvement, especially in correctly identifying all students who may dropout (sensitivity).
-   Good F1 Score: The F1 score, which balances precision and recall, is quite high at 90.5%, indicating that the model is generally well-balanced between precision and recall, but could benefit from improved recall.

```{r}

# Train the logistic regression model
model_lr <- glm(y_train ~ Admission.grade + Curricular.units.1st.sem..evaluations.  , family = binomial(link = "logit"), data = as.data.frame(x_train))

# Summarize the model
summary(model_lr)

```

```{r}
# Predicting probabilities
probabilities_lr <- predict(model_lr, newdata = as.data.frame(x_test), type = "response")

# Converting probabilities to binary outcome based on a threshold of 0.5
y_pred_lr <- ifelse(probabilities_lr > 0.5, 1, 0)

# Convert the predictions to a factor for consistency with y_test
y_pred_lr <- factor(y_pred_lr, levels = c(0, 1))

```

```{r}
# Evaluate the model performance using the 'perform' function we defined earlier
perform(y_pred_lr, y_test)
```

```{r Confusion Matrix LR}

library(ggplot2)

# Create the confusion matrix
conf_matrix <- table(Predicted = y_pred_lr, True = y_test)

# Convert the matrix to a data frame for plotting
conf_matrix_df <- as.data.frame(as.table(conf_matrix))

# Create labels for the plot
levels(conf_matrix_df$True) <- c("Dropout", "Non-Dropout")
levels(conf_matrix_df$Predicted) <- c("Dropout", "Non-Dropout")

# Plot the confusion matrix
ggplot(data = conf_matrix_df, aes(x = Predicted, y = True, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = Freq), vjust = 1.5, color = "black") +
  scale_fill_gradient(low = "orange", high = "green") +
  labs(x = "Predicted Label", y = "True Label") +
  theme_minimal() +
  labs(title = "Logistic Regression: Confusion Matrix") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

**Observations:**

-   High Recall, Low Precision for the Non-Dropout Class: The model has a recall of 98% for the non-dropout class, indicating it is highly effective at identifying actual non-dropouts. However, the precision is 0%, showing that when the model predicts non-dropout, it is incorrect all the time. This discrepancy suggests that the model is over-predicting the non-dropout class.
-   Accuracy Deception: While the model has an overall accuracy of 73.7%, this metric doesn't reflect the true performance due to the imbalanced prediction towards one class. The model failed to identify any true dropouts, as indicated by the 0% sensitivity for the dropout class.
-   F1 Score and Balanced Accuracy Limitation: The F1 score for the dropout class could not be computed (NaN) due to a zero precision value. Balanced accuracy is at 49%, indicating that the model does not perform well on a balanced dataset.
-   Misleading Prevalence: The prevalence of the dropout class is 24.8%, but the model's detection rate for this class is 0%, showing that it could not correctly identify any of the dropouts.
-   Model Improvement Needs: The model needs significant improvement. It is currently biased towards predicting non-dropouts, missing all dropout cases. This could be due to class imbalance in the training data or the model not being tuned correctly to recognize patterns associated with dropouts. Addressing these issues with more balanced data, feature engineering, or model tuning would be essential steps to improve performance.

## Support Vector Classifier

```{r}
# Train the SVM model with a linear kernel
model_svc <- svm(x_train, y_train, type = 'C-classification', kernel = 'linear', cost = 0.1, scale = FALSE)

# Summary of the model
summary(model_svc)

```

```{r}
# Make predictions on the test set
y_pred_svc <- predict(model_svc, x_test)
```

```{r}
perform(y_test, y_pred_svc) 
```

```{r}
library(ggplot2)

# Create the confusion matrix
conf_matrix <- table(Predicted = y_pred_svc, True = y_test)

# Convert the matrix to a data frame for plotting
conf_matrix_df <- as.data.frame(as.table(conf_matrix))

# Create labels for the plot
levels(conf_matrix_df$True) <- c("Dropout", "Non-Dropout")
levels(conf_matrix_df$Predicted) <- c("Dropout", "Non-Dropout")

# Plot the confusion matrix
ggplot(data = conf_matrix_df, aes(x = Predicted, y = True, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = Freq), vjust = 1.5, color = "black") +
  scale_fill_gradient(low = "orange", high = "green") +
  labs(x = "Predicted Label", y = "True Label") +
  theme_minimal() +
  labs(title = "SVC Regression: Confusion Matrix") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

**Observations:**

-   High Precision for Non-Dropout Predictions: The model demonstrates a high precision of 92.7% for predicting non-dropouts, which means that when the model predicts a student will not dropout, it is very likely to be correct.
-   Good Recall for Non-Dropouts: The recall for non-dropouts is 86%, indicating the model is quite capable of identifying the majority of students who will not dropout. However, there is still a notable portion of non-dropout students (14%) that the model fails to identify.
-   Overall Accuracy: The model achieves an accuracy of 83.2%, suggesting that it is correct in its predictions more than four-fifths of the time. This is a solid performance, but it does leave some room for improvement, particularly in reducing false negatives and false positives.
-   F1 Score: The F1 score, which balances precision and recall, stands at 89.2%. This high value suggests that the model maintains a good balance between precision and recall; however, it leans slightly more towards precision.
-   Balanced Accuracy: The balanced accuracy is 78.5%, which is a more reliable metric than standard accuracy in scenarios with imbalanced classes. It shows that the model is fairly good at treating both classes (dropout and non-dropout) equally, but with some bias towards non-dropout predictions.

## KNN Classifier

```{r}
# Install and load necessary packages if they are not already installed
# install.packages("class")
library(class)

# Prepare an empty vector to store the accuracy scores
accuracy_scores <- numeric(39)

# Loop over K values from 1 to 39
for (i in 1:39) {
  # Train the KNN model using the knn function from the class package
  # Note: knn expects both training and test data to be matrices
  pred_i <- knn(train = as.matrix(x_train), test = as.matrix(x_test), cl = y_train, k = i)
  
  # Calculate accuracy
  accuracy <- sum(y_test == pred_i) / length(y_test)
  
  # Store accuracy in the vector
  accuracy_scores[i] <- accuracy
}

# Inspect the accuracy scores
print(accuracy_scores)
```

```{r}
# Install and load necessary packages if they are not already installed
# install.packages("ggplot2")
library(ggplot2)

# Create a data frame for plotting
accuracy_data <- data.frame(K_Value = 1:39, Accuracy = accuracy_scores)

# Create the plot
accuracy_plot <- ggplot(accuracy_data, aes(x = K_Value, y = Accuracy)) +
  geom_line(color = 'red') +
  geom_point(color = 'blue', size = 3, shape = 1) +
  ggtitle('Accuracy by K Value for KNN') +
  xlab('K Value') +
  ylab('Accuracy') +
  theme_minimal()

# Print the plot
print(accuracy_plot)

```

```{r}
# Install and load the kknn package if it's not already installed
if (!requireNamespace("kknn", quietly = TRUE)) {
    install.packages("kknn")
}
library(kknn)

# Train the KNN model with k = 16
model_knn <- kknn(formula = as.factor(y_train) ~ ., train = as.data.frame(x_train), test = as.data.frame(x_test), k = 16, distance = 2, scale = FALSE)

# Summarize the model
summary(model_knn)

```

```{r}
# Make predictions on the test set using the KNN model
# Note that 'predict' function will return factors if it's a classification problem
y_pred_knn <- predict(model_knn, newdata = as.data.frame(x_test))

# There is no need to apply a threshold as we're not dealing with probabilities
# 'y_pred_knn' will already be a factor with levels corresponding to the classes

# If you need to ensure that 'y_pred_knn' has the same levels as 'y_train', you can do:
y_pred_knn <- factor(y_pred_knn, levels = levels(factor(y_train)))

# Now, you can pass 'y_pred_knn' to your performance evaluation function
# perform(y_test, y_pred_knn) # Uncomment this line if your 'perform' function is ready

```

```{r}
perform(y_pred_knn, y_test)
```

```{r}
library(ggplot2)

# Create the confusion matrix
conf_matrix <- table(Predicted = y_pred_knn, True = y_test)

# Convert the matrix to a data frame for plotting
conf_matrix_df <- as.data.frame(as.table(conf_matrix))

# Create labels for the plot
levels(conf_matrix_df$True) <- c("Dropout", "Non-Dropout")
levels(conf_matrix_df$Predicted) <- c("Dropout", "Non-Dropout")

# Plot the confusion matrix
ggplot(data = conf_matrix_df, aes(x = Predicted, y = True, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = Freq), vjust = 1.5, color = "black") +
  scale_fill_gradient(low = "orange", high = "green") +
  labs(x = "Predicted Label", y = "True Label") +
  theme_minimal() +
  labs(title = "Logistic Regression: Confusion Matrix") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

**Observations:**

-   Model Performance: The KNN model correctly predicted 88 non-dropouts and 424 dropouts. However, there were 61 non-dropouts incorrectly predicted as dropouts, and 27 dropouts incorrectly predicted as non-dropouts. This indicates that while the model is quite good at identifying dropouts, it can sometimes confuse non-dropouts as dropouts.
-   Accuracy: The accuracy of the model is about 85.3%, which means that in general, the model correctly predicted whether a student would drop out or not about 85 times out of 100.
-   Precision and Recall: Precision for dropouts is relatively high (around 87.4%), which means that when the model predicts a student will drop out, it is correct most of the time. The recall is even higher (94%), indicating that the model is quite good at identifying most of the actual dropout cases.
-   F1 Score: The F1 score, which is a balance between precision and recall, is about 90.6%. This is a strong score that suggests the model has a good balance between correctly predicting dropouts and minimizing false dropout predictions.
-   Practical Implications: For a school administrator using this model, it suggests they can have a good degree of trust in the model's predictions about which students might drop out. This can help in targeting interventions more effectively. However, the model is not perfect, so it should not be the sole basis for any significant decision about a student's academic future.

```{r}
# Assuming you have the necessary library installed
library(ggplot2)

ggplot(df, aes(x = Age.at.enrollment)) +
  geom_histogram(binwidth = 1, fill = "skyblue", color = "white") +
  labs(x = "Age at Enrollment", y = "Number Of Students", title = "Distribution of Age at Enrollment")

```
